{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv; load_dotenv(find_dotenv())\n",
    "import os, notion_client, requests, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional\n",
    "from operator import itemgetter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.document_loaders.html import UnstructuredHTMLLoader\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function, convert_to_openai_tool\n",
    "\n",
    "notion = notion_client.Client(auth=os.environ['NOTION_TOKEN'])\n",
    "CLIP = os.environ['CLIP_DATABASE_ID']\n",
    "INPUT = os.environ['INPUT_DATABASE_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_database = notion.databases.retrieve(database_id=INPUT)\n",
    "tags = [o['name'] for o in input_database['properties']['Tags']['multi_select']['options']]\n",
    "types = [o['name'] for o in input_database['properties']['Type']['multi_select']['options']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'PageProperties',\n",
       " 'description': 'Extract web page data',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'title': {'description': 'page title (long ver.)',\n",
       "    'type': 'string'},\n",
       "   'short_title': {'description': 'page title (short ver.)', 'type': 'string'},\n",
       "   'year': {'description': 'Posted year of the page', 'type': 'integer'},\n",
       "   'month': {'description': 'Posted month of the page', 'type': 'integer'},\n",
       "   'types': {'description': 'page types in list. You can create new.',\n",
       "    'enum': ['Tweet',\n",
       "     'Announce',\n",
       "     'Slides',\n",
       "     'Medium',\n",
       "     'Web',\n",
       "     'Qiita',\n",
       "     'Zenn',\n",
       "     'Notion',\n",
       "     'note',\n",
       "     'Book',\n",
       "     'Paper',\n",
       "     'GitHub',\n",
       "     'HuggingFace',\n",
       "     'Demo',\n",
       "     'KAKEN',\n",
       "     'Course',\n",
       "     'Tutorial',\n",
       "     'Resources',\n",
       "     'GPTs',\n",
       "     'Thought',\n",
       "     'Youtube',\n",
       "     'Webinar',\n",
       "     'Kaggle',\n",
       "     'Service',\n",
       "     'MemberOnly',\n",
       "     'Note'],\n",
       "    'type': 'array',\n",
       "    'items': {'type': 'string'}},\n",
       "   'tags': {'description': 'tags in list. You can create new in Camel case.',\n",
       "    'enum': ['LLM',\n",
       "     'LLMEval',\n",
       "     'LLMOps',\n",
       "     'Agent',\n",
       "     'ChatGPT',\n",
       "     'OpenAI',\n",
       "     'VoiceInteraction',\n",
       "     'Prompt',\n",
       "     'GA',\n",
       "     'Guardrails',\n",
       "     'LangChain',\n",
       "     'SoftDev',\n",
       "     'OpenLLM',\n",
       "     'AWS',\n",
       "     'Life',\n",
       "     'CustomInstructions',\n",
       "     'Survey',\n",
       "     'Azure',\n",
       "     'Embedding',\n",
       "     'Visualization',\n",
       "     'Conversation',\n",
       "     'Robotics',\n",
       "     'Container',\n",
       "     'FastAPI',\n",
       "     'Reseach',\n",
       "     'Python',\n",
       "     'Database',\n",
       "     'RAG',\n",
       "     'OpenSearch',\n",
       "     'SQL',\n",
       "     'GPT4V',\n",
       "     'StableDiffusion',\n",
       "     'Logging',\n",
       "     'DX',\n",
       "     'ECS',\n",
       "     'Geo',\n",
       "     'Infrastructure',\n",
       "     'Kaggle',\n",
       "     'LangSmith',\n",
       "     'PromptHub',\n",
       "     'PromptRefine',\n",
       "     'Notion',\n",
       "     'LLMTuning',\n",
       "     'Rec',\n",
       "     'PrivateDev',\n",
       "     'English',\n",
       "     'SelfManagement',\n",
       "     'Chat',\n",
       "     'KnowledgeGraph',\n",
       "     'IaC',\n",
       "     'UIdev',\n",
       "     'AssistantsAPI',\n",
       "     'ML',\n",
       "     'HitL',\n",
       "     'QueryTrans',\n",
       "     'Decision',\n",
       "     'GPTs',\n",
       "     'Experiments',\n",
       "     'JsonMode',\n",
       "     'OpenInterpreter',\n",
       "     'Flutter',\n",
       "     'Service',\n",
       "     'MySQL',\n",
       "     'ChatInteraction',\n",
       "     'Copilot',\n",
       "     'Cursor',\n",
       "     'Docker',\n",
       "     'MultiModal',\n",
       "     'MongoDB',\n",
       "     'ROS',\n",
       "     'Wearable',\n",
       "     'DataAnalysis',\n",
       "     'Google',\n",
       "     'Vision',\n",
       "     'Gemini',\n",
       "     'HCI',\n",
       "     'MQ3',\n",
       "     'XR',\n",
       "     'Unity',\n",
       "     'guidance',\n",
       "     'NLP',\n",
       "     'Philosophy',\n",
       "     'Work',\n",
       "     'DDD',\n",
       "     'Drawing',\n",
       "     'JavaScript',\n",
       "     'MoE',\n",
       "     'Career',\n",
       "     'LlamaIndex',\n",
       "     'GenerativeAI',\n",
       "     'Manifold',\n",
       "     'OCR',\n",
       "     'Bandit',\n",
       "     'CausalInference',\n",
       "     'PromptInjection',\n",
       "     'CodeInterpreter',\n",
       "     'Food',\n",
       "     'Whisper',\n",
       "     'Sports',\n",
       "     'Claude',\n",
       "     'CodeLLM',\n",
       "     'Bedrock',\n",
       "     'Search',\n",
       "     'LLMSecurity',\n",
       "     'ReactNative',\n",
       "     'UX',\n",
       "     'Dataset',\n",
       "     'Translate',\n",
       "     'WebSearch',\n",
       "     'GNN',\n",
       "     'API',\n",
       "     'Twitter',\n",
       "     'AI',\n",
       "     'Innovation',\n",
       "     'Zenn',\n",
       "     'LLMAgent',\n",
       "     'Research',\n",
       "     'Demo',\n",
       "     'EducationAI'],\n",
       "    'type': 'array',\n",
       "    'items': {'type': 'string'}},\n",
       "   'summary': {'description': 'page content in Japanese.', 'type': 'string'}},\n",
       "  'required': ['title', 'short_title', 'types', 'tags', 'summary']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PageProperties(BaseModel):\n",
    "    \"\"\"Extract web page data\"\"\"\n",
    "    title: str = Field(..., description='page title (long ver.)')\n",
    "    short_title: str = Field(..., description='page title (short ver.)')\n",
    "    year: Optional[int] = Field(description='Posted year of the page')\n",
    "    month: Optional[int] = Field(description='Posted month of the page')\n",
    "    # date: Optional[datetime.date] = Field(description='Posted date of the page in format \"%Y/%m/%d\"')\n",
    "    types: list[str] = Field(..., description='page types in list. You can create new.', enum=types)\n",
    "    tags: list[str] = Field(..., description='tags in list. You can create new in Camel case.', enum=tags)\n",
    "    summary: str = Field(..., description='page content in Japanese.')\n",
    "    # code: Optional[str] = Field(description='link url to the Code. (Github, GitLab, ...)')\n",
    "    # pdf: Optional[str] = Field(description='link url to the PDF.')\n",
    "\n",
    "extract_func = convert_to_openai_function(PageProperties)\n",
    "extract_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def get_tweet_content_and_links(tweet_url):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    # ChromeDriverのパスを指定\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # URLにアクセス\n",
    "    driver.get(tweet_url)\n",
    "\n",
    "    # articleタグが読み込まれるまで待機（最大15秒）\n",
    "    WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.TAG_NAME, 'article')))\n",
    "\n",
    "    # ページのソースを取得して解析\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Tweet本文とリンクを取得\n",
    "    tweet_text = \"\"\n",
    "    tweet_links = []\n",
    "    tweet_container = soup.find(\"div\", {\"data-testid\": \"tweetText\"})\n",
    "    if tweet_container:\n",
    "        tweet_text = tweet_container.get_text()\n",
    "        links = tweet_container.find_all(\"a\")\n",
    "        for link in links:\n",
    "            tweet_links.append(link['href'])\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return tweet_text, tweet_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(url):\n",
    "    headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "    urls = data.find_all('a', href=True)\n",
    "    return urls\n",
    "\n",
    "def extract_text(url):\n",
    "    response = requests.get(url)\n",
    "    with open('.temp.html','w') as f:\n",
    "        f.write(response.text)\n",
    "    loader = UnstructuredHTMLLoader(\".temp.html\")\n",
    "    docs = loader.load()\n",
    "    content = docs[0].page_content.replace('\\n\\n', '\\n')\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_web_text(url: str):\n",
    "    if url.startswith('https://x.com/'):\n",
    "        content, links = get_tweet_content_and_links(url)\n",
    "    else:\n",
    "        content = extract_text(url)\n",
    "        # links = extract_urls(url)\n",
    "    return content\n",
    "\n",
    "def create_page(data):\n",
    "    url = data['url']\n",
    "    x = data['page']\n",
    "    types = [{'name': typ} for typ in x['types']] if isinstance(x['types'], list) else [{'name': x['types']}]\n",
    "    tags = [{'name': tag} for tag in x['tags']] if isinstance(x['tags'], list) else [{'name': x['tags']}]\n",
    "    page = {\n",
    "        \"parent\": { \"database_id\": INPUT},\n",
    "        \"properties\": {\n",
    "            'Status': {'status': {'name': 'Not started'}},\n",
    "            'Import': {'checkbox': True},\n",
    "            'URL': {'url': url},\n",
    "            'Issue': {'title': [{'text': {'content': x['short_title']}}]},\n",
    "            'Type': {\"multi_select\": types},\n",
    "            'Tags': {\"multi_select\": tags},\n",
    "            'Abstract': {'rich_text': [{'text': {'content': x['summary']}}]},\n",
    "            'Title': {'rich_text': [{'text': {'content': x['title']}}]},\n",
    "        }\n",
    "    }\n",
    "    if 'year' in x:\n",
    "        year = []\n",
    "        if x['year'] >= 2023:\n",
    "            if 'month' in x:\n",
    "                year.append({'name': f\"{str(x['year']).zfill(4)}.{str(x['month']).zfill(2)}\"}),\n",
    "                year.append({'name': str(x['year'])})\n",
    "        else:\n",
    "            year.append({'name': str(x['year'])})\n",
    "        if year:\n",
    "            page['properties']['Year'] = {\"multi_select\": year}\n",
    "    return page\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "model_with_func = model.bind_functions([extract_func])\n",
    "\n",
    "system_images_extract = '''\\\n",
    "You are a data extractor from a web page.\n",
    "'''\n",
    "\n",
    "template = '''\\\n",
    "## SourceURL\n",
    "{source_url}\n",
    "\n",
    "## WebText\n",
    "{web_text}\n",
    "'''\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=system_images_extract),\n",
    "    HumanMessagePromptTemplate.from_template(template),\n",
    "])\n",
    "\n",
    "chain = {\n",
    "    'source_url': RunnablePassthrough(),\n",
    "    'web_text': RunnablePassthrough() | RunnableLambda(load_web_text),\n",
    "    'urls': RunnablePassthrough() | RunnableLambda(extract_urls),\n",
    "} | RunnablePassthrough() \\\n",
    "| {\n",
    "    'url': itemgetter('source_url'),\n",
    "    'page': RunnablePassthrough() | chat_template | model_with_func | JsonOutputFunctionsParser()\n",
    "}\\\n",
    "| RunnableLambda(create_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:07<11:44,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body failed validation: body.children[0].image.external should be defined, instead was `undefined`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:11<20:21, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body failed validation: body.children[24].image.external.url.length should be ≤ `2000`, instead was `10738`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:24<14:37, 10.45s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "items = notion.databases.query(database_id=CLIP, filter={\n",
    "    \"property\": \"Check\",\"checkbox\":{\"equals\": False}\n",
    "})\n",
    "for item in tqdm(items['results']):\n",
    "    try:\n",
    "        url = item['properties']['URL']['url']\n",
    "        page = chain.invoke(url)\n",
    "        blocks = notion.blocks.children.list(block_id=item['id'])\n",
    "        page['children'] = blocks['results']\n",
    "        notion.pages.create(**page)\n",
    "        notion.blocks.delete(block_id=item['id'])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'results': [{'object': 'block',\n",
       "   'id': '04586813-aee7-4ab5-9ffe-ff49fb09f6c5',\n",
       "   'parent': {'type': 'page_id',\n",
       "    'page_id': '525e3deb-c6c7-4cdf-b884-5414fc68be9b'},\n",
       "   'created_time': '2024-05-19T15:07:00.000Z',\n",
       "   'last_edited_time': '2024-05-19T15:07:00.000Z',\n",
       "   'created_by': {'object': 'user',\n",
       "    'id': 'f51f285e-16d4-41fe-ab93-750d33107cb3'},\n",
       "   'last_edited_by': {'object': 'user',\n",
       "    'id': 'f51f285e-16d4-41fe-ab93-750d33107cb3'},\n",
       "   'has_children': False,\n",
       "   'archived': False,\n",
       "   'in_trash': False,\n",
       "   'type': 'image',\n",
       "   'image': {'caption': [],\n",
       "    'type': 'file',\n",
       "    'file': {'url': 'https://prod-files-secure.s3.us-west-2.amazonaws.com/36f2205a-559e-4a1f-973b-38bea623c469/42bd8dc6-a30f-4ddc-ac65-a87cb49b5144/slide_0.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20240521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20240521T013751Z&X-Amz-Expires=3600&X-Amz-Signature=c8f1c141f7d39a6434b20f20a4969fe5c90691482cfd146aae87d142947b9ebc&X-Amz-SignedHeaders=host&x-id=GetObject',\n",
       "     'expiry_time': '2024-05-21T02:37:51.305Z'}}}],\n",
       " 'next_cursor': None,\n",
       " 'has_more': False,\n",
       " 'type': 'block',\n",
       " 'block': {},\n",
       " 'request_id': '0616024f-8b2a-400b-957c-f649bba23be5'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
